{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BSPvRMB7zxNo",
        "Va1TEh5d3J69",
        "0RPm0uUA3fo4",
        "6Kyp5nys3Phx",
        "Y7Vzc5Rl34TO"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPyp4LpAII5lde6VKfBWxGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b0a30e5a0ac49f4b7fac4263defff66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9a5ff0758864913818ff705d1b59c5d",
              "IPY_MODEL_d99e3f15eca24d3f9943db3a19013515",
              "IPY_MODEL_fee10d8af2174f638c884ae1efd25720"
            ],
            "layout": "IPY_MODEL_2f4f21925ae54b09b017f445825ac7f1"
          }
        },
        "f9a5ff0758864913818ff705d1b59c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f020930d9dca4a6698a138fce4200ceb",
            "placeholder": "​",
            "style": "IPY_MODEL_f3f51a83052541c6bc2b33be8be78e9d",
            "value": "Transcribing: 100%"
          }
        },
        "d99e3f15eca24d3f9943db3a19013515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e525d7f65dd345c5af0fd8a42c7284aa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d75e3a4578e942419b78be588fed1b3e",
            "value": 1
          }
        },
        "fee10d8af2174f638c884ae1efd25720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a2c1070730a435c99f51e1d4acfe01d",
            "placeholder": "​",
            "style": "IPY_MODEL_1adbc1821fd24607b04be454a4d1c7f4",
            "value": " 1/1 [00:01&lt;00:00,  1.91s/it]"
          }
        },
        "2f4f21925ae54b09b017f445825ac7f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f020930d9dca4a6698a138fce4200ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f51a83052541c6bc2b33be8be78e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e525d7f65dd345c5af0fd8a42c7284aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75e3a4578e942419b78be588fed1b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a2c1070730a435c99f51e1d4acfe01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1adbc1821fd24607b04be454a4d1c7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoungsikMoon/FORS/blob/main/%EB%AC%B8%EC%98%81%EC%8B%9D/FORS_%EB%AC%B8%EC%98%81%EC%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCM 파일 핸들링 코드 모음"
      ],
      "metadata": {
        "id": "BSPvRMB7zxNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 : https://noggame.tistory.com/15"
      ],
      "metadata": {
        "id": "8yM5lSw3lGYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pcm을 wav로 변환하는 코드"
      ],
      "metadata": {
        "id": "Va1TEh5d3J69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCM 데이터를 WAV로 변환하려는 경우 WAV 파일이 어떻게 쓰였는지 나타내는 Header가 필요하다. Header에는 samplerate나 소리 데이터의 길이 등의 정보가 들어가며, 직접 구현하기보다는 numpy, librosa, soundfile 등의 라이브러리를 사용하면 간단히 해결 가능하다."
      ],
      "metadata": {
        "id": "G2wf4yXo3YmC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vnZltD4vWnc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa as lr\n",
        "import soundfile as sf\n",
        "\n",
        "target = \"/content/KsponSpeech_000001.pcm\" # 타깃 파일 경로\n",
        "destinationPath = \"/content/KsponSpeech_000001.wav\" #만들 파일 경로\n",
        "buf = None\n",
        "\n",
        "with open(target, 'rb') as tf:\n",
        "    buf = tf.read()\n",
        "    buf = buf+b'0' if len(buf)%2 else buf    # padding 0 (경우에 따라서 PCM 파일의 길이가 8bit[1byte]로 나누어 떨어지지 않는 경우가 있어 0으로 패딩값을 더해준다, 해당 처리를 하지 않는 경우 numpy나 librosa 라이브러리 사용 시 오류가 날 수 있다)\n",
        "\n",
        "pcm_data = np.frombuffer(buf, dtype='int16')\n",
        "wav_data = lr.util.buf_to_float(x=pcm_data, n_bytes=2)\n",
        "sf.write(destinationPath, wav_data, 16000, format='WAV', endian='LITTLE', subtype='PCM_16')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wav 파일을 pcm 으로 변환하는 코드"
      ],
      "metadata": {
        "id": "0RPm0uUA3fo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCM과 WAV의 소리 데이터 부분은 동일하고, Header 부분만 차이가 나므로 WAV 파일에서 (Header를 제외한) 데이터 부분만 읽어서 파일로 만들면 PCM 파일에 해당한다."
      ],
      "metadata": {
        "id": "te0Wut9j3jUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"{대상파일_경로}\"\n",
        "destinationPath = target[:-4]+\".pcm\" # {생성파일경로}\n",
        "buf = None\n",
        "\n",
        "with open(destinationPath, \"wb\") as d_file:\n",
        "    t_file = open(target, \"rb\")\n",
        "    t_bin = t_file.read()\n",
        "    d_file.write(t_bin[44:])    # header 이외의 데이터를 pcm 파일로 저장\n",
        "    t_file.close()"
      ],
      "metadata": {
        "id": "yLEEiO-z3lvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pcm 파일 통합 하는 코드"
      ],
      "metadata": {
        "id": "6Kyp5nys3Phx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCM은 파일의 시작에 소리 정보를 담고있는 header가 존재하지 않기 때문에, raw 데이터(Byte Code)를 그대로 읽어서 합치면된다."
      ],
      "metadata": {
        "id": "DlAgEc_u3T2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetList = [\"{대상파일1_경로}\", \"{대상파일2_경로}\"]\n",
        "destinationPath = \"{생성파일경로}\"\n",
        "\n",
        "buf = bytearray()\n",
        "for file in targetList:\n",
        "    f = open(file, 'rb')\n",
        "    buf += f.read()\n",
        "    f.close()\n",
        "\n",
        "wf = open(destinationPath, 'wb')\n",
        "wf.write(buf)\n",
        "wf.close()"
      ],
      "metadata": {
        "id": "iAspxFVq3Rlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2heEAzdd4mqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI WhisperAI STT (오래걸림)"
      ],
      "metadata": {
        "id": "Y7Vzc5Rl34TO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위스퍼 설치"
      ],
      "metadata": {
        "id": "mNMys_Cb3_qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper"
      ],
      "metadata": {
        "id": "PXtGSoRn4HPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "한국어 모델 다운로드하기"
      ],
      "metadata": {
        "id": "2DcnomBi4RUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper-cli --model ko --download-dir ."
      ],
      "metadata": {
        "id": "gGFhiDDv4J78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "음성 파일 변환하기\n",
        "\n",
        "변환할 한국어 음성 파일을 준비합니다.\n",
        "다음 Python 코드를 실행하여 음성 파일을 텍스트로 변환합니다:"
      ],
      "metadata": {
        "id": "2-zi2Pmw4Shj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# 모델 로드\n",
        "model = whisper.load_model(\"small\")\n"
      ],
      "metadata": {
        "id": "IeWSlvU94ZOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 확인하기\n",
        "\n",
        "위 코드를 실행하면 음성 파일의 텍스트 인식 결과가 출력됩니다.\n",
        "인식 결과는 result['text']에 저장됩니다.\n",
        "\n",
        "OpenAI Whisper는 다양한 언어를 지원하며, 특히 한국어 모델의 성능이 우수합니다. 이를 활용하면 다양한 음성 기반 애플리케이션을 개발할 수 있습니다.\n",
        "\n",
        "추가로, Whisper는 다음과 같은 특징이 있습니다:\n",
        "\n",
        "지원 언어: 총 98개 언어 지원 (한국어 포함)\n",
        "\n",
        "모델 크기: 작은 모델부터 대형 모델까지 다양한 옵션 제공\n",
        "\n",
        "사용 요금: 무료로 사용 가능\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jUo2zqF54g3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 음성 파일 경로 설정\n",
        "audio_file = \"/content/KsponSpeech_000001.wav\"\n",
        "\n",
        "# 음성 파일 변환\n",
        "result = model.transcribe(audio_file)\n",
        "print(f\"인식 결과: {result['text']}\")"
      ],
      "metadata": {
        "id": "XsW_vqAe55Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Zw6EDoIBlMs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NVIDIA NeMo STT (1초)"
      ],
      "metadata": {
        "id": "xM9_wFVTlNXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 git : https://github.com/NVIDIA/NeMo"
      ],
      "metadata": {
        "id": "TcfPyQ8jFN3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 문서 : https://huggingface.co/eesungkim/stt_kr_conformer_transducer_large"
      ],
      "metadata": {
        "id": "OHv83v4rlQF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 훈련하고, 미세 조정하고, 플레이하려면 NVIDIA NeMo를 설치해야 합니다 . 최신 Pytorch 버전을 설치한 후 설치하는 것이 좋습니다."
      ],
      "metadata": {
        "id": "6cgkkStP7uTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nemo_toolkit['all']"
      ],
      "metadata": {
        "id": "YF79GRhW69L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 모델은 NeMo 툴킷[1](https://github.com/NVIDIA/NeMo)에서 사용할 수 있으며 추론을 위해 사전 훈련된 체크포인트로 사용하거나 다른 데이터 세트에 대한 미세 조정을 수행할 수 있습니다.\n"
      ],
      "metadata": {
        "id": "co1pUE467xLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "자동으로 모델 인스턴스화"
      ],
      "metadata": {
        "id": "_YHR4nzD78Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nemo.collections.asr as nemo_asr\n",
        "asr_model = nemo_asr.models.ASRModel.from_pretrained(\"eesungkim/stt_kr_conformer_transducer_large\")"
      ],
      "metadata": {
        "id": "kkJqcr3g7w0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "음성파일 텍스트로 전환"
      ],
      "metadata": {
        "id": "nrvCdPMiE1B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "asr_model.transcribe(['KsponSpeech_000001.wav'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "0b0a30e5a0ac49f4b7fac4263defff66",
            "f9a5ff0758864913818ff705d1b59c5d",
            "d99e3f15eca24d3f9943db3a19013515",
            "fee10d8af2174f638c884ae1efd25720",
            "2f4f21925ae54b09b017f445825ac7f1",
            "f020930d9dca4a6698a138fce4200ceb",
            "f3f51a83052541c6bc2b33be8be78e9d",
            "e525d7f65dd345c5af0fd8a42c7284aa",
            "d75e3a4578e942419b78be588fed1b3e",
            "7a2c1070730a435c99f51e1d4acfe01d",
            "1adbc1821fd24607b04be454a4d1c7f4"
          ]
        },
        "id": "I2qGFgcCArOv",
        "outputId": "5bbc19d8-bc5c-4495-d316-246ae18688b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b0a30e5a0ac49f4b7fac4263defff66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['아 뭔 소리야 그건 또'], ['아 뭔 소리야 그건 또'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "많은 오디오 파일을 텍스트로 변환"
      ],
      "metadata": {
        "id": "O1lO9YjyA0qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python [NEMO_GIT_FOLDER]/examples/asr/transcribe_speech.py  pretrained_name=\"eesungkim/stt_kr_conformer_transducer_large\"  audio_dir=\"<오디오 디렉터리>\""
      ],
      "metadata": {
        "id": "yPTqUIomA2ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 음성메모 프로그램 만들기"
      ],
      "metadata": {
        "id": "NT64zzQz3yON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 : https://pagichacha.tistory.com/103"
      ],
      "metadata": {
        "id": "_AuTy9An445z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "음성으로 말을하면 자동으로 기록해주는 메모 프로그램.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7snOSPuk37kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "시나리오\n",
        "\n",
        "1. 음성내용을 텍스트로  변환 후 파일 메모로 저장.\n",
        "- 안내방송 (텍스트-음성 처리) 후 우리가 음성으로 말한 내용을 텍스ㅡ트로 변환 후 파일로 저장하는 방법에 대하여 살펴봅시다.\n",
        "\n",
        "2. 위 1번 내용에서 음성이 끝나기 전까지 지속적으로 녹음되도록 개선\n",
        "- 위의 1번의 경우 한번 말하면 끝이 나므로 다시 프로그램을 시작해야 하는 불편사항이 존재합니다. 따라서 우리가 특정 명령을 내리기 저까지는 계속 실행되어 메모를 진행할 수 있도록 대선하는 방법에 대하여 알아보겠습니다.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WN0n-eRq4QuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "프로그램 실행하기 위한 모듈 임포트."
      ],
      "metadata": {
        "id": "fSDvVamk5d4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition #음성인식"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6PhkF4F5qMP",
        "outputId": "6456dd58-f70c-4cb0-be68-bb3dfb8aff28"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting install\n",
            "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
            "Installing collected packages: install, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.3 install-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS #텍스트를 음성으로 만들 수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eo3mUBx65wp",
        "outputId": "5097db78-31d1-4112-c103-ee7727070672"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygame #음성 재생 기능"
      ],
      "metadata": {
        "id": "qlxnMnyVHo-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import time\n",
        "import pygame\n",
        "import os"
      ],
      "metadata": {
        "id": "BgoOYwlM5hi8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def speak(text):\n",
        "    tts = gTTS(text=text, lang='ko')\n",
        "    filename='voice.mp3'\n",
        "    tts.save(filename)\n",
        "    pygame.init()\n",
        "    pygame.mixer.music.load(filename)\n",
        "    pygame.mixer.music.play()\n",
        "    while pygame.mixer.music.get_busy():\n",
        "        continue\n",
        "    pygame.mixer.music.unload()\n",
        "    time.sleep(1) # 1초 지연\n",
        "    os.remove(filename)\n",
        "\n",
        "\n",
        "def get_audio():\n",
        "    r = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"지금 말씀하세요: \")\n",
        "        audio = r.listen(source)\n",
        "        said = \" \"\n",
        "\n",
        "        try:\n",
        "            said = r.recognize_google(audio, language=\"ko-KR\")\n",
        "            print(\"말씀하신 내용입니다 : \", said)\n",
        "        except Exception as e:\n",
        "            print(\"Exception: \" + str(e))\n",
        "\n",
        "    return said\n",
        "\n",
        "#############################\n",
        "# 0.안내 방송(음성)\n",
        "#############################\n",
        "if os.path.isfile('memo.txt'):\n",
        "    os.remove('memo.txt')\n",
        "speak(\"안녕하세요. 2초 후에 말씀하세요. 종료시 굿바이 라고 말씀하시면 됩니다.\")\n",
        "\n",
        "while True:\n",
        "#############################\n",
        "# 1.음성입력\n",
        "#############################\n",
        "    text=get_audio()\n",
        "    print(text)\n",
        "\n",
        "#############################\n",
        "# 5.파일저장\n",
        "#############################\n",
        "    with open('memo.txt', 'a') as f:\n",
        "        f.write(str(text)+\"\\n\")\n",
        "\n",
        "    if \"굿바이\" in text:\n",
        "        break\n",
        "\n",
        "time.sleep(0.1)"
      ],
      "metadata": {
        "id": "CEauAGjtHiej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset 라이브러리의 load_datasets 함수 분석"
      ],
      "metadata": {
        "id": "gmHxXCBDi98H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastWhisper 파인튜닝할 때 모질라의 commonvoice 라는 음성 코퍼스를 불러온다.\n",
        "이 때 commonvoice를 load_datasets 함수로 불러오는데 어떻게 불러오는지 연구한다.\n",
        "방법을 알면 우리의 음성코퍼스도 학습 시킬 수 있을것으로 생각된다.\n"
      ],
      "metadata": {
        "id": "rn7GrIXvjFZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(\n",
        "    path: str,\n",
        "    name: Optional[str] = None,\n",
        "    data_dir: Optional[str] = None,\n",
        "    data_files: Optional[Union[str, Sequence[str], Mapping[str, Union[str, Sequence[str]]]]] = None,\n",
        "    split: Optional[Union[str, Split]] = None,\n",
        "    cache_dir: Optional[str] = None,\n",
        "    features: Optional[Features] = None,\n",
        "    download_config: Optional[DownloadConfig] = None,\n",
        "    download_mode: Optional[Union[DownloadMode, str]] = None,\n",
        "    verification_mode: Optional[Union[VerificationMode, str]] = None,\n",
        "    ignore_verifications=\"deprecated\",\n",
        "    keep_in_memory: Optional[bool] = None,\n",
        "    save_infos: bool = False,\n",
        "    revision: Optional[Union[str, Version]] = None,\n",
        "    token: Optional[Union[bool, str]] = None,\n",
        "    use_auth_token=\"deprecated\",\n",
        "    task=\"deprecated\",\n",
        "    streaming: bool = False,\n",
        "    num_proc: Optional[int] = None,\n",
        "    storage_options: Optional[Dict] = None,\n",
        "    trust_remote_code: bool = None,\n",
        "    **config_kwargs,\n",
        ") -> Union[DatasetDict, Dataset, IterableDatasetDict, IterableDataset]:\n",
        "    \"\"\"Load a dataset from the Hugging Face Hub, or a local dataset.\n",
        "\n",
        "    You can find the list of datasets on the [Hub](https://huggingface.co/datasets) or with [`huggingface_hub.list_datasets`].\n",
        "\n",
        "    A dataset is a directory that contains:\n",
        "\n",
        "    - some data files in generic formats (JSON, CSV, Parquet, text, etc.).\n",
        "    - and optionally a dataset script, if it requires some code to read the data files. This is used to load any kind of formats or structures.\n",
        "\n",
        "    Note that dataset scripts can also download and read data files from anywhere - in case your data files already exist online.\n",
        "\n",
        "    This function does the following under the hood:\n",
        "\n",
        "        1. Download and import in the library the dataset script from `path` if it's not already cached inside the library.\n",
        "\n",
        "            If the dataset has no dataset script, then a generic dataset script is imported instead (JSON, CSV, Parquet, text, etc.)\n",
        "\n",
        "            Dataset scripts are small python scripts that define dataset builders. They define the citation, info and format of the dataset,\n",
        "            contain the path or URL to the original data files and the code to load examples from the original data files.\n",
        "\n",
        "            You can find the complete list of datasets in the Datasets [Hub](https://huggingface.co/datasets).\n",
        "\n",
        "        2. Run the dataset script which will:\n",
        "\n",
        "            * Download the dataset file from the original URL (see the script) if it's not already available locally or cached.\n",
        "            * Process and cache the dataset in typed Arrow tables for caching.\n",
        "\n",
        "                Arrow table are arbitrarily long, typed tables which can store nested objects and be mapped to numpy/pandas/python generic types.\n",
        "                They can be directly accessed from disk, loaded in RAM or even streamed over the web.\n",
        "\n",
        "        3. Return a dataset built from the requested splits in `split` (default: all).\n",
        "\n",
        "    It also allows to load a dataset from a local directory or a dataset repository on the Hugging Face Hub without dataset script.\n",
        "    In this case, it automatically loads all the data files from the directory or the dataset repository.\n",
        "\n",
        "    Args:\n",
        "\n",
        "        path (`str`):\n",
        "            Path or name of the dataset.\n",
        "            Depending on `path`, the dataset builder that is used comes from a generic dataset script (JSON, CSV, Parquet, text etc.) or from the dataset script (a python file) inside the dataset directory.\n",
        "\n",
        "            For local datasets:\n",
        "\n",
        "            - if `path` is a local directory (containing data files only)\n",
        "              -> load a generic dataset builder (csv, json, text etc.) based on the content of the directory\n",
        "              e.g. `'./path/to/directory/with/my/csv/data'`.\n",
        "            - if `path` is a local dataset script or a directory containing a local dataset script (if the script has the same name as the directory)\n",
        "              -> load the dataset builder from the dataset script\n",
        "              e.g. `'./dataset/squad'` or `'./dataset/squad/squad.py'`.\n",
        "\n",
        "            For datasets on the Hugging Face Hub (list all available datasets with [`huggingface_hub.list_datasets`])\n",
        "\n",
        "            - if `path` is a dataset repository on the HF hub (containing data files only)\n",
        "              -> load a generic dataset builder (csv, text etc.) based on the content of the repository\n",
        "              e.g. `'username/dataset_name'`, a dataset repository on the HF hub containing your data files.\n",
        "            - if `path` is a dataset repository on the HF hub with a dataset script (if the script has the same name as the directory)\n",
        "              -> load the dataset builder from the dataset script in the dataset repository\n",
        "              e.g. `glue`, `squad`, `'username/dataset_name'`, a dataset repository on the HF hub containing a dataset script `'dataset_name.py'`.\n",
        "\n",
        "        name (`str`, *optional*):\n",
        "            Defining the name of the dataset configuration.\n",
        "        data_dir (`str`, *optional*):\n",
        "            Defining the `data_dir` of the dataset configuration. If specified for the generic builders (csv, text etc.) or the Hub datasets and `data_files` is `None`,\n",
        "            the behavior is equal to passing `os.path.join(data_dir, **)` as `data_files` to reference all the files in a directory.\n",
        "        data_files (`str` or `Sequence` or `Mapping`, *optional*):\n",
        "            Path(s) to source data file(s).\n",
        "        split (`Split` or `str`):\n",
        "            Which split of the data to load.\n",
        "            If `None`, will return a `dict` with all splits (typically `datasets.Split.TRAIN` and `datasets.Split.TEST`).\n",
        "            If given, will return a single Dataset.\n",
        "            Splits can be combined and specified like in tensorflow-datasets.\n",
        "        cache_dir (`str`, *optional*):\n",
        "            Directory to read/write data. Defaults to `\"~/.cache/huggingface/datasets\"`.\n",
        "        features (`Features`, *optional*):\n",
        "            Set the features type to use for this dataset.\n",
        "        download_config ([`DownloadConfig`], *optional*):\n",
        "            Specific download configuration parameters.\n",
        "        download_mode ([`DownloadMode`] or `str`, defaults to `REUSE_DATASET_IF_EXISTS`):\n",
        "            Download/generate mode.\n",
        "        verification_mode ([`VerificationMode`] or `str`, defaults to `BASIC_CHECKS`):\n",
        "            Verification mode determining the checks to run on the downloaded/processed dataset information (checksums/size/splits/...).\n",
        "\n",
        "            <Added version=\"2.9.1\"/>\n",
        "        ignore_verifications (`bool`, defaults to `False`):\n",
        "            Ignore the verifications of the downloaded/processed dataset information (checksums/size/splits/...).\n",
        "\n",
        "            <Deprecated version=\"2.9.1\">\n",
        "\n",
        "            `ignore_verifications` was deprecated in version 2.9.1 and will be removed in 3.0.0.\n",
        "            Please use `verification_mode` instead.\n",
        "\n",
        "            </Deprecated>\n",
        "        keep_in_memory (`bool`, defaults to `None`):\n",
        "            Whether to copy the dataset in-memory. If `None`, the dataset\n",
        "            will not be copied in-memory unless explicitly enabled by setting `datasets.config.IN_MEMORY_MAX_SIZE` to\n",
        "            nonzero. See more details in the [improve performance](../cache#improve-performance) section.\n",
        "        save_infos (`bool`, defaults to `False`):\n",
        "            Save the dataset information (checksums/size/splits/...).\n",
        "        revision ([`Version`] or `str`, *optional*):\n",
        "            Version of the dataset script to load.\n",
        "            As datasets have their own git repository on the Datasets Hub, the default version \"main\" corresponds to their \"main\" branch.\n",
        "            You can specify a different version than the default \"main\" by using a commit SHA or a git tag of the dataset repository.\n",
        "        token (`str` or `bool`, *optional*):\n",
        "            Optional string or boolean to use as Bearer token for remote files on the Datasets Hub.\n",
        "            If `True`, or not specified, will get token from `\"~/.huggingface\"`.\n",
        "        use_auth_token (`str` or `bool`, *optional*):\n",
        "            Optional string or boolean to use as Bearer token for remote files on the Datasets Hub.\n",
        "            If `True`, or not specified, will get token from `\"~/.huggingface\"`.\n",
        "\n",
        "            <Deprecated version=\"2.14.0\">\n",
        "\n",
        "            `use_auth_token` was deprecated in favor of `token` in version 2.14.0 and will be removed in 3.0.0.\n",
        "\n",
        "            </Deprecated>\n",
        "        task (`str`):\n",
        "            The task to prepare the dataset for during training and evaluation. Casts the dataset's [`Features`] to standardized column names and types as detailed in `datasets.tasks`.\n",
        "\n",
        "            <Deprecated version=\"2.13.0\">\n",
        "\n",
        "            `task` was deprecated in version 2.13.0 and will be removed in 3.0.0.\n",
        "\n",
        "            </Deprecated>\n",
        "        streaming (`bool`, defaults to `False`):\n",
        "            If set to `True`, don't download the data files. Instead, it streams the data progressively while\n",
        "            iterating on the dataset. An [`IterableDataset`] or [`IterableDatasetDict`] is returned instead in this case.\n",
        "\n",
        "            Note that streaming works for datasets that use data formats that support being iterated over like txt, csv, jsonl for example.\n",
        "            Json files may be downloaded completely. Also streaming from remote zip or gzip files is supported but other compressed formats\n",
        "            like rar and xz are not yet supported. The tgz format doesn't allow streaming.\n",
        "        num_proc (`int`, *optional*, defaults to `None`):\n",
        "            Number of processes when downloading and generating the dataset locally.\n",
        "            Multiprocessing is disabled by default.\n",
        "\n",
        "            <Added version=\"2.7.0\"/>\n",
        "        storage_options (`dict`, *optional*, defaults to `None`):\n",
        "            **Experimental**. Key/value pairs to be passed on to the dataset file-system backend, if any.\n",
        "\n",
        "            <Added version=\"2.11.0\"/>\n",
        "        trust_remote_code (`bool`, defaults to `True`):\n",
        "            Whether or not to allow for datasets defined on the Hub using a dataset script. This option\n",
        "            should only be set to `True` for repositories you trust and in which you have read the code, as it will\n",
        "            execute code present on the Hub on your local machine.\n",
        "\n",
        "            <Tip warning={true}>\n",
        "\n",
        "            `trust_remote_code` will default to False in the next major release.\n",
        "\n",
        "            </Tip>\n",
        "\n",
        "            <Added version=\"2.16.0\"/>\n",
        "        **config_kwargs (additional keyword arguments):\n",
        "            Keyword arguments to be passed to the `BuilderConfig`\n",
        "            and used in the [`DatasetBuilder`].\n",
        "\n",
        "    Returns:\n",
        "        [`Dataset`] or [`DatasetDict`]:\n",
        "        - if `split` is not `None`: the dataset requested,\n",
        "        - if `split` is `None`, a [`~datasets.DatasetDict`] with each split.\n",
        "\n",
        "        or [`IterableDataset`] or [`IterableDatasetDict`]: if `streaming=True`\n",
        "\n",
        "        - if `split` is not `None`, the dataset is requested\n",
        "        - if `split` is `None`, a [`~datasets.streaming.IterableDatasetDict`] with each split.\n",
        "\n",
        "    Example:\n",
        "\n",
        "    Load a dataset from the Hugging Face Hub:\n",
        "\n",
        "    ```py\n",
        "    >>> from datasets import load_dataset\n",
        "    >>> ds = load_dataset('rotten_tomatoes', split='train')\n",
        "\n",
        "    # Map data files to splits\n",
        "    >>> data_files = {'train': 'train.csv', 'test': 'test.csv'}\n",
        "    >>> ds = load_dataset('namespace/your_dataset_name', data_files=data_files)\n",
        "    ```\n",
        "\n",
        "    Load a local dataset:\n",
        "\n",
        "    ```py\n",
        "    # Load a CSV file\n",
        "    >>> from datasets import load_dataset\n",
        "    >>> ds = load_dataset('csv', data_files='path/to/local/my_dataset.csv')\n",
        "\n",
        "    # Load a JSON file\n",
        "    >>> from datasets import load_dataset\n",
        "    >>> ds = load_dataset('json', data_files='path/to/local/my_dataset.json')\n",
        "\n",
        "    # Load from a local loading script\n",
        "    >>> from datasets import load_dataset\n",
        "    >>> ds = load_dataset('path/to/local/loading_script/loading_script.py', split='train')\n",
        "    ```\n",
        "\n",
        "    Load an [`~datasets.IterableDataset`]:\n",
        "\n",
        "    ```py\n",
        "    >>> from datasets import load_dataset\n",
        "    >>> ds = load_dataset('rotten_tomatoes', split='train', streaming=True)\n",
        "    ```\n",
        "\n",
        "    Load an image dataset with the `ImageFolder` dataset builder:\n",
        "\n",
        "    ```py\n",
        "    >>> from datasets import load_dataset\n",
        "    >>> ds = load_dataset('imagefolder', data_dir='/path/to/images', split='train')\n",
        "    ```\n",
        "    \"\"\"\n",
        "    if use_auth_token != \"deprecated\":\n",
        "        warnings.warn(\n",
        "            \"'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\\n\"\n",
        "            \"You can remove this warning by passing 'token=<use_auth_token>' instead.\",\n",
        "            FutureWarning,\n",
        "        )\n",
        "        token = use_auth_token\n",
        "    if ignore_verifications != \"deprecated\":\n",
        "        verification_mode = VerificationMode.NO_CHECKS if ignore_verifications else VerificationMode.ALL_CHECKS\n",
        "        warnings.warn(\n",
        "            \"'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\\n\"\n",
        "            f\"You can remove this warning by passing 'verification_mode={verification_mode.value}' instead.\",\n",
        "            FutureWarning,\n",
        "        )\n",
        "    if task != \"deprecated\":\n",
        "        warnings.warn(\n",
        "            \"'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\\n\",\n",
        "            FutureWarning,\n",
        "        )\n",
        "    else:\n",
        "        task = None\n",
        "    if data_files is not None and not data_files:\n",
        "        raise ValueError(f\"Empty 'data_files': '{data_files}'. It should be either non-empty or None (default).\")\n",
        "    if Path(path, config.DATASET_STATE_JSON_FILENAME).exists():\n",
        "        raise ValueError(\n",
        "            \"You are trying to load a dataset that was saved using `save_to_disk`. \"\n",
        "            \"Please use `load_from_disk` instead.\"\n",
        "        )\n",
        "\n",
        "    if streaming and num_proc is not None:\n",
        "        raise NotImplementedError(\n",
        "            \"Loading a streaming dataset in parallel with `num_proc` is not implemented. \"\n",
        "            \"To parallelize streaming, you can wrap the dataset with a PyTorch DataLoader using `num_workers` > 1 instead.\"\n",
        "        )\n",
        "\n",
        "    download_mode = DownloadMode(download_mode or DownloadMode.REUSE_DATASET_IF_EXISTS)\n",
        "    verification_mode = VerificationMode(\n",
        "        (verification_mode or VerificationMode.BASIC_CHECKS) if not save_infos else VerificationMode.ALL_CHECKS\n",
        "    )\n",
        "\n",
        "    # Create a dataset builder\n",
        "    builder_instance = load_dataset_builder(\n",
        "        path=path,\n",
        "        name=name,\n",
        "        data_dir=data_dir,\n",
        "        data_files=data_files,\n",
        "        cache_dir=cache_dir,\n",
        "        features=features,\n",
        "        download_config=download_config,\n",
        "        download_mode=download_mode,\n",
        "        revision=revision,\n",
        "        token=token,\n",
        "        storage_options=storage_options,\n",
        "        trust_remote_code=trust_remote_code,\n",
        "        _require_default_config_name=name is None,\n",
        "        **config_kwargs,\n",
        "    )\n",
        "\n",
        "    # Return iterable dataset in case of streaming\n",
        "    if streaming:\n",
        "        return builder_instance.as_streaming_dataset(split=split)\n",
        "\n",
        "    # Some datasets are already processed on the HF google storage\n",
        "    # Don't try downloading from Google storage for the packaged datasets as text, json, csv or pandas\n",
        "    try_from_hf_gcs = path not in _PACKAGED_DATASETS_MODULES\n",
        "\n",
        "    # Download and prepare data\n",
        "    builder_instance.download_and_prepare(\n",
        "        download_config=download_config,\n",
        "        download_mode=download_mode,\n",
        "        verification_mode=verification_mode,\n",
        "        try_from_hf_gcs=try_from_hf_gcs,\n",
        "        num_proc=num_proc,\n",
        "        storage_options=storage_options,\n",
        "    )\n",
        "\n",
        "    # Build dataset for splits\n",
        "    keep_in_memory = (\n",
        "        keep_in_memory if keep_in_memory is not None else is_small_dataset(builder_instance.info.dataset_size)\n",
        "    )\n",
        "    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)\n",
        "    # Rename and cast features to match task schema\n",
        "    if task is not None:\n",
        "        # To avoid issuing the same warning twice\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\", FutureWarning)\n",
        "            ds = ds.prepare_for_task(task)\n",
        "    if save_infos:\n",
        "        builder_instance._save_infos()\n",
        "\n",
        "    return ds"
      ],
      "metadata": {
        "id": "cUWeKjDTjiv4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}