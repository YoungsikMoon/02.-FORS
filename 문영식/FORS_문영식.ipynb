{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BSPvRMB7zxNo",
        "Va1TEh5d3J69",
        "0RPm0uUA3fo4",
        "6Kyp5nys3Phx",
        "Y7Vzc5Rl34TO"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPwJAu+UzQAKgLhve7Q6yb1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b0a30e5a0ac49f4b7fac4263defff66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9a5ff0758864913818ff705d1b59c5d",
              "IPY_MODEL_d99e3f15eca24d3f9943db3a19013515",
              "IPY_MODEL_fee10d8af2174f638c884ae1efd25720"
            ],
            "layout": "IPY_MODEL_2f4f21925ae54b09b017f445825ac7f1"
          }
        },
        "f9a5ff0758864913818ff705d1b59c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f020930d9dca4a6698a138fce4200ceb",
            "placeholder": "​",
            "style": "IPY_MODEL_f3f51a83052541c6bc2b33be8be78e9d",
            "value": "Transcribing: 100%"
          }
        },
        "d99e3f15eca24d3f9943db3a19013515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e525d7f65dd345c5af0fd8a42c7284aa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d75e3a4578e942419b78be588fed1b3e",
            "value": 1
          }
        },
        "fee10d8af2174f638c884ae1efd25720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a2c1070730a435c99f51e1d4acfe01d",
            "placeholder": "​",
            "style": "IPY_MODEL_1adbc1821fd24607b04be454a4d1c7f4",
            "value": " 1/1 [00:01&lt;00:00,  1.91s/it]"
          }
        },
        "2f4f21925ae54b09b017f445825ac7f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f020930d9dca4a6698a138fce4200ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f51a83052541c6bc2b33be8be78e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e525d7f65dd345c5af0fd8a42c7284aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75e3a4578e942419b78be588fed1b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a2c1070730a435c99f51e1d4acfe01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1adbc1821fd24607b04be454a4d1c7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoungsikMoon/FORS/blob/main/%EB%AC%B8%EC%98%81%EC%8B%9D/FORS_%EB%AC%B8%EC%98%81%EC%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "오버라이드 테스트2"
      ],
      "metadata": {
        "id": "Vbv1QpaWBWwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCM 파일 핸들링 코드 모음"
      ],
      "metadata": {
        "id": "BSPvRMB7zxNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 : https://noggame.tistory.com/15"
      ],
      "metadata": {
        "id": "8yM5lSw3lGYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pcm을 wav로 변환하는 코드"
      ],
      "metadata": {
        "id": "Va1TEh5d3J69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCM 데이터를 WAV로 변환하려는 경우 WAV 파일이 어떻게 쓰였는지 나타내는 Header가 필요하다. Header에는 samplerate나 소리 데이터의 길이 등의 정보가 들어가며, 직접 구현하기보다는 numpy, librosa, soundfile 등의 라이브러리를 사용하면 간단히 해결 가능하다."
      ],
      "metadata": {
        "id": "G2wf4yXo3YmC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vnZltD4vWnc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa as lr\n",
        "import soundfile as sf\n",
        "\n",
        "target = \"/content/KsponSpeech_000001.pcm\" # 타깃 파일 경로\n",
        "destinationPath = \"/content/KsponSpeech_000001.wav\" #만들 파일 경로\n",
        "buf = None\n",
        "\n",
        "with open(target, 'rb') as tf:\n",
        "    buf = tf.read()\n",
        "    buf = buf+b'0' if len(buf)%2 else buf    # padding 0 (경우에 따라서 PCM 파일의 길이가 8bit[1byte]로 나누어 떨어지지 않는 경우가 있어 0으로 패딩값을 더해준다, 해당 처리를 하지 않는 경우 numpy나 librosa 라이브러리 사용 시 오류가 날 수 있다)\n",
        "\n",
        "pcm_data = np.frombuffer(buf, dtype='int16')\n",
        "wav_data = lr.util.buf_to_float(x=pcm_data, n_bytes=2)\n",
        "sf.write(destinationPath, wav_data, 16000, format='WAV', endian='LITTLE', subtype='PCM_16')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wav 파일을 pcm 으로 변환하는 코드"
      ],
      "metadata": {
        "id": "0RPm0uUA3fo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCM과 WAV의 소리 데이터 부분은 동일하고, Header 부분만 차이가 나므로 WAV 파일에서 (Header를 제외한) 데이터 부분만 읽어서 파일로 만들면 PCM 파일에 해당한다."
      ],
      "metadata": {
        "id": "te0Wut9j3jUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"{대상파일_경로}\"\n",
        "destinationPath = target[:-4]+\".pcm\" # {생성파일경로}\n",
        "buf = None\n",
        "\n",
        "with open(destinationPath, \"wb\") as d_file:\n",
        "    t_file = open(target, \"rb\")\n",
        "    t_bin = t_file.read()\n",
        "    d_file.write(t_bin[44:])    # header 이외의 데이터를 pcm 파일로 저장\n",
        "    t_file.close()"
      ],
      "metadata": {
        "id": "yLEEiO-z3lvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pcm 파일 통합 하는 코드"
      ],
      "metadata": {
        "id": "6Kyp5nys3Phx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCM은 파일의 시작에 소리 정보를 담고있는 header가 존재하지 않기 때문에, raw 데이터(Byte Code)를 그대로 읽어서 합치면된다."
      ],
      "metadata": {
        "id": "DlAgEc_u3T2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetList = [\"{대상파일1_경로}\", \"{대상파일2_경로}\"]\n",
        "destinationPath = \"{생성파일경로}\"\n",
        "\n",
        "buf = bytearray()\n",
        "for file in targetList:\n",
        "    f = open(file, 'rb')\n",
        "    buf += f.read()\n",
        "    f.close()\n",
        "\n",
        "wf = open(destinationPath, 'wb')\n",
        "wf.write(buf)\n",
        "wf.close()"
      ],
      "metadata": {
        "id": "iAspxFVq3Rlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2heEAzdd4mqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI WhisperAI STT (오래걸림)"
      ],
      "metadata": {
        "id": "Y7Vzc5Rl34TO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위스퍼 설치"
      ],
      "metadata": {
        "id": "mNMys_Cb3_qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper"
      ],
      "metadata": {
        "id": "PXtGSoRn4HPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "한국어 모델 다운로드하기"
      ],
      "metadata": {
        "id": "2DcnomBi4RUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper-cli --model ko --download-dir ."
      ],
      "metadata": {
        "id": "gGFhiDDv4J78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "음성 파일 변환하기\n",
        "\n",
        "변환할 한국어 음성 파일을 준비합니다.\n",
        "다음 Python 코드를 실행하여 음성 파일을 텍스트로 변환합니다:"
      ],
      "metadata": {
        "id": "2-zi2Pmw4Shj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# 모델 로드\n",
        "model = whisper.load_model(\"small\")\n"
      ],
      "metadata": {
        "id": "IeWSlvU94ZOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 확인하기\n",
        "\n",
        "위 코드를 실행하면 음성 파일의 텍스트 인식 결과가 출력됩니다.\n",
        "인식 결과는 result['text']에 저장됩니다.\n",
        "\n",
        "OpenAI Whisper는 다양한 언어를 지원하며, 특히 한국어 모델의 성능이 우수합니다. 이를 활용하면 다양한 음성 기반 애플리케이션을 개발할 수 있습니다.\n",
        "\n",
        "추가로, Whisper는 다음과 같은 특징이 있습니다:\n",
        "\n",
        "지원 언어: 총 98개 언어 지원 (한국어 포함)\n",
        "\n",
        "모델 크기: 작은 모델부터 대형 모델까지 다양한 옵션 제공\n",
        "\n",
        "사용 요금: 무료로 사용 가능\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jUo2zqF54g3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 음성 파일 경로 설정\n",
        "audio_file = \"/content/KsponSpeech_000001.wav\"\n",
        "\n",
        "# 음성 파일 변환\n",
        "result = model.transcribe(audio_file)\n",
        "print(f\"인식 결과: {result['text']}\")"
      ],
      "metadata": {
        "id": "XsW_vqAe55Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Zw6EDoIBlMs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NVIDIA NeMo STT (1초)"
      ],
      "metadata": {
        "id": "xM9_wFVTlNXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 git : https://github.com/NVIDIA/NeMo"
      ],
      "metadata": {
        "id": "TcfPyQ8jFN3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 문서 : https://huggingface.co/eesungkim/stt_kr_conformer_transducer_large"
      ],
      "metadata": {
        "id": "OHv83v4rlQF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 훈련하고, 미세 조정하고, 플레이하려면 NVIDIA NeMo를 설치해야 합니다 . 최신 Pytorch 버전을 설치한 후 설치하는 것이 좋습니다."
      ],
      "metadata": {
        "id": "6cgkkStP7uTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nemo_toolkit['all']"
      ],
      "metadata": {
        "id": "YF79GRhW69L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 모델은 NeMo 툴킷[1](https://github.com/NVIDIA/NeMo)에서 사용할 수 있으며 추론을 위해 사전 훈련된 체크포인트로 사용하거나 다른 데이터 세트에 대한 미세 조정을 수행할 수 있습니다.\n"
      ],
      "metadata": {
        "id": "co1pUE467xLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "자동으로 모델 인스턴스화"
      ],
      "metadata": {
        "id": "_YHR4nzD78Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nemo.collections.asr as nemo_asr\n",
        "asr_model = nemo_asr.models.ASRModel.from_pretrained(\"eesungkim/stt_kr_conformer_transducer_large\")"
      ],
      "metadata": {
        "id": "kkJqcr3g7w0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "음성파일 텍스트로 전환"
      ],
      "metadata": {
        "id": "nrvCdPMiE1B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "asr_model.transcribe(['KsponSpeech_000001.wav'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "0b0a30e5a0ac49f4b7fac4263defff66",
            "f9a5ff0758864913818ff705d1b59c5d",
            "d99e3f15eca24d3f9943db3a19013515",
            "fee10d8af2174f638c884ae1efd25720",
            "2f4f21925ae54b09b017f445825ac7f1",
            "f020930d9dca4a6698a138fce4200ceb",
            "f3f51a83052541c6bc2b33be8be78e9d",
            "e525d7f65dd345c5af0fd8a42c7284aa",
            "d75e3a4578e942419b78be588fed1b3e",
            "7a2c1070730a435c99f51e1d4acfe01d",
            "1adbc1821fd24607b04be454a4d1c7f4"
          ]
        },
        "id": "I2qGFgcCArOv",
        "outputId": "5bbc19d8-bc5c-4495-d316-246ae18688b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b0a30e5a0ac49f4b7fac4263defff66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['아 뭔 소리야 그건 또'], ['아 뭔 소리야 그건 또'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "많은 오디오 파일을 텍스트로 변환"
      ],
      "metadata": {
        "id": "O1lO9YjyA0qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python [NEMO_GIT_FOLDER]/examples/asr/transcribe_speech.py  pretrained_name=\"eesungkim/stt_kr_conformer_transducer_large\"  audio_dir=\"<오디오 디렉터리>\""
      ],
      "metadata": {
        "id": "yPTqUIomA2ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 음성메모 프로그램 만들기"
      ],
      "metadata": {
        "id": "NT64zzQz3yON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 : https://pagichacha.tistory.com/103"
      ],
      "metadata": {
        "id": "_AuTy9An445z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "음성으로 말을하면 자동으로 기록해주는 메모 프로그램.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7snOSPuk37kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "시나리오\n",
        "\n",
        "1. 음성내용을 텍스트로  변환 후 파일 메모로 저장.\n",
        "- 안내방송 (텍스트-음성 처리) 후 우리가 음성으로 말한 내용을 텍스ㅡ트로 변환 후 파일로 저장하는 방법에 대하여 살펴봅시다.\n",
        "\n",
        "2. 위 1번 내용에서 음성이 끝나기 전까지 지속적으로 녹음되도록 개선\n",
        "- 위의 1번의 경우 한번 말하면 끝이 나므로 다시 프로그램을 시작해야 하는 불편사항이 존재합니다. 따라서 우리가 특정 명령을 내리기 저까지는 계속 실행되어 메모를 진행할 수 있도록 대선하는 방법에 대하여 알아보겠습니다.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WN0n-eRq4QuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "프로그램 실행하기 위한 모듈 임포트."
      ],
      "metadata": {
        "id": "fSDvVamk5d4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition #음성인식"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6PhkF4F5qMP",
        "outputId": "6456dd58-f70c-4cb0-be68-bb3dfb8aff28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting install\n",
            "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
            "Installing collected packages: install, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.3 install-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS #텍스트를 음성으로 만들 수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eo3mUBx65wp",
        "outputId": "5097db78-31d1-4112-c103-ee7727070672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygame #음성 재생 기능"
      ],
      "metadata": {
        "id": "qlxnMnyVHo-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import time\n",
        "import pygame\n",
        "import os"
      ],
      "metadata": {
        "id": "BgoOYwlM5hi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def speak(text):\n",
        "    tts = gTTS(text=text, lang='ko')\n",
        "    filename='voice.mp3'\n",
        "    tts.save(filename)\n",
        "    pygame.init()\n",
        "    pygame.mixer.music.load(filename)\n",
        "    pygame.mixer.music.play()\n",
        "    while pygame.mixer.music.get_busy():\n",
        "        continue\n",
        "    pygame.mixer.music.unload()\n",
        "    time.sleep(1) # 1초 지연\n",
        "    os.remove(filename)\n",
        "\n",
        "\n",
        "def get_audio():\n",
        "    r = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"지금 말씀하세요: \")\n",
        "        audio = r.listen(source)\n",
        "        said = \" \"\n",
        "\n",
        "        try:\n",
        "            said = r.recognize_google(audio, language=\"ko-KR\")\n",
        "            print(\"말씀하신 내용입니다 : \", said)\n",
        "        except Exception as e:\n",
        "            print(\"Exception: \" + str(e))\n",
        "\n",
        "    return said\n",
        "\n",
        "#############################\n",
        "# 0.안내 방송(음성)\n",
        "#############################\n",
        "if os.path.isfile('memo.txt'):\n",
        "    os.remove('memo.txt')\n",
        "speak(\"안녕하세요. 2초 후에 말씀하세요. 종료시 굿바이 라고 말씀하시면 됩니다.\")\n",
        "\n",
        "while True:\n",
        "#############################\n",
        "# 1.음성입력\n",
        "#############################\n",
        "    text=get_audio()\n",
        "    print(text)\n",
        "\n",
        "#############################\n",
        "# 5.파일저장\n",
        "#############################\n",
        "    with open('memo.txt', 'a') as f:\n",
        "        f.write(str(text)+\"\\n\")\n",
        "\n",
        "    if \"굿바이\" in text:\n",
        "        break\n",
        "\n",
        "time.sleep(0.1)"
      ],
      "metadata": {
        "id": "CEauAGjtHiej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}